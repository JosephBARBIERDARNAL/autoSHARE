{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all datasets properties and store them\n",
    "\n",
    "### Code\n",
    "\n",
    "The following code **iterates over all files** in the root directory containing all SHARE datasets. It extracts the properties of each dataset and stores them in a pandas dataframe. The properties are:\n",
    "- dataset name\n",
    "- number of rows\n",
    "- number of columns\n",
    "- column names\n",
    "\n",
    "### Details\n",
    "\n",
    "- For some reason, one or multiple files, when trying to read them, throw a `ValueError`. However, `pandas` gives us the solution by telling us we should add `convert_categoricals=False` to the `read_csv` function when this is happening. This is the reason why we have a `try` and `except` block in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:20,  8.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# initiate constants\n",
    "directory = 'data/'\n",
    "file_names = []\n",
    "waves = []\n",
    "n_rows = []\n",
    "n_columns = []\n",
    "columns = []\n",
    "\n",
    "# iterate through all files in the directory\n",
    "for root, dirs, files in tqdm(os.walk(directory)):\n",
    "    for file in files:\n",
    "        if file.endswith('.dta'):\n",
    "            try:\n",
    "                dataset = pd.read_stata(os.path.join(root, file))\n",
    "            except ValueError:\n",
    "                dataset = pd.read_stata(os.path.join(root, file), convert_categoricals=False)\n",
    "            file_names.append(file)\n",
    "            waves.append(file[6])\n",
    "            n_rows.append(len(dataset))\n",
    "            n_columns.append(len(dataset.columns))\n",
    "            columns.append(list(dataset.columns))\n",
    "\n",
    "# create a dataframe with the results\n",
    "df = pd.DataFrame({\n",
    "    'file_name': file_names,\n",
    "    'wave': waves,\n",
    "    'n_rows': n_rows,\n",
    "    'n_columns': n_columns,\n",
    "    'columns': columns\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminate normal and particular datasets\n",
    "\n",
    "According to the [official documentation](https://share-eric.eu/data/faqs-support):\n",
    "\n",
    "*\"The naming of variables is harmonised across waves. Variable names in the CAPI instrument data use the following format: mmXXXyyy_LL. “mm” is the module identifier, e.g. DN for the demographics module, “XXX” refers to the question number, e.g. 001, and “yyy” are optional digits for dummy variables (indicated by “d”), euro conversion (indicated by “e”) or unfolding brackets (indicated by “ub”). The separation character “_” is followed by “LL” optional digits for category or loop indication (“outer loop”).\"*\n",
    "\n",
    "For this reason, we add **boolean indicator** columns to the dataframe to discriminate normal datasets from particular ones. This allows us to see that approximately 10% of the datasets are particular, and maybe useless for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_normal(file_name: str, only_gv: bool=True) -> bool:\n",
    "    \"\"\"\n",
    "    Detect if the last 3 elements of the string follow the pattern _ab, \n",
    "    where 'a' and 'b' are single letters.\n",
    "    \n",
    "    Args:\n",
    "    - file_name (str): The string to be checked.\n",
    "    Returns:\n",
    "    - bool: True if the pattern is found, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # special case the General Variables files\n",
    "    if '_gv_' in file_name:\n",
    "        return True\n",
    "    \n",
    "    if only_gv:\n",
    "        return False\n",
    "    \n",
    "    # remove file extension\n",
    "    suffix = file_name[:-4]\n",
    "\n",
    "    # check if the suffix is long enough\n",
    "    if len(suffix) < 3:\n",
    "        return False\n",
    "    \n",
    "    # check if the last three elements follow the pattern\n",
    "    last_three = suffix[-3:]\n",
    "    if last_three[0] == '_' and last_three[1].isalpha() and last_three[2].isalpha():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# filter out the files that are not normal\n",
    "df['is_normal'] = df['file_name'].apply(is_file_normal, only_gv=False)\n",
    "df['is_gv'] = df['file_name'].apply(is_file_normal, only_gv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_normal\n",
      "True     89.43\n",
      "False    10.57\n",
      "Name: count, dtype: float64\n",
      "\n",
      "is_gv\n",
      "False    77.36\n",
      "True     22.64\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(round(df.is_normal.value_counts()/len(df)*100,2))\n",
    "print()\n",
    "print(round(df.is_gv.value_counts()/len(df)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>wave</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_columns</th>\n",
       "      <th>columns</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>is_gv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>sharew7_rel8-0-0_dq.dta</td>\n",
       "      <td>7</td>\n",
       "      <td>77202</td>\n",
       "      <td>255</td>\n",
       "      <td>[mergeid, hhid7, mergeidp7, coupleid7, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sharew3_rel8-0-0_st.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>28463</td>\n",
       "      <td>12</td>\n",
       "      <td>[mergeid, hhid3, mergeidp3, coupleid3, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sharew1_rel8-0-0_gv_exrates.dta</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>[country, euro, currency, exrate_w1, exrate_w2...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>sharew3_rel8-0-0_gv_exrates.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>[country, euro, currency, exrate_w1, exrate_w2...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sharew1_rel8-0-0_hc.dta</td>\n",
       "      <td>1</td>\n",
       "      <td>30419</td>\n",
       "      <td>157</td>\n",
       "      <td>[mergeid, hhid1, mergeidp1, coupleid1, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>sharew7_rel8-0-0_ph.dta</td>\n",
       "      <td>7</td>\n",
       "      <td>77202</td>\n",
       "      <td>196</td>\n",
       "      <td>[mergeid, hhid7, mergeidp7, coupleid7, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>sharew6_rel8-0-0_gv_weights.dta</td>\n",
       "      <td>6</td>\n",
       "      <td>68085</td>\n",
       "      <td>14</td>\n",
       "      <td>[mergeid, hhid6, mergeidp6, coupleid6, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>sharew3_rel8-0-0_gl.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>28463</td>\n",
       "      <td>90</td>\n",
       "      <td>[mergeid, hhid3, mergeidp3, coupleid3, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>sharew8_rel8-0-0_gs.dta</td>\n",
       "      <td>8</td>\n",
       "      <td>46733</td>\n",
       "      <td>23</td>\n",
       "      <td>[mergeid, hhid8, mergeidp8, coupleid8, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>sharew8_rel8-0-0_hh.dta</td>\n",
       "      <td>8</td>\n",
       "      <td>46733</td>\n",
       "      <td>20</td>\n",
       "      <td>[mergeid, hhid8, mergeidp8, coupleid8, country...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name wave  n_rows  n_columns  \\\n",
       "225          sharew7_rel8-0-0_dq.dta    7   77202        255   \n",
       "111          sharew3_rel8-0-0_st.dta    3   28463         12   \n",
       "3    sharew1_rel8-0-0_gv_exrates.dta    1      29         69   \n",
       "114  sharew3_rel8-0-0_gv_exrates.dta    3      29         69   \n",
       "21           sharew1_rel8-0-0_hc.dta    1   30419        157   \n",
       "194          sharew7_rel8-0-0_ph.dta    7   77202        196   \n",
       "139  sharew6_rel8-0-0_gv_weights.dta    6   68085         14   \n",
       "105          sharew3_rel8-0-0_gl.dta    3   28463         90   \n",
       "159          sharew8_rel8-0-0_gs.dta    8   46733         23   \n",
       "160          sharew8_rel8-0-0_hh.dta    8   46733         20   \n",
       "\n",
       "                                               columns  is_normal  is_gv  \n",
       "225  [mergeid, hhid7, mergeidp7, coupleid7, country...       True  False  \n",
       "111  [mergeid, hhid3, mergeidp3, coupleid3, country...       True  False  \n",
       "3    [country, euro, currency, exrate_w1, exrate_w2...       True   True  \n",
       "114  [country, euro, currency, exrate_w1, exrate_w2...       True   True  \n",
       "21   [mergeid, hhid1, mergeidp1, coupleid1, country...       True  False  \n",
       "194  [mergeid, hhid7, mergeidp7, coupleid7, country...       True  False  \n",
       "139  [mergeid, hhid6, mergeidp6, coupleid6, country...       True   True  \n",
       "105  [mergeid, hhid3, mergeidp3, coupleid3, country...       True  False  \n",
       "159  [mergeid, hhid8, mergeidp8, coupleid8, country...       True  False  \n",
       "160  [mergeid, hhid8, mergeidp8, coupleid8, country...       True  False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the dataframe to a csv file\n",
    "df.to_csv('data_info.csv', index=False)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get column names for each wave\n",
    "\n",
    "We store the column names for each wave in `.txt` files, so we can use them later. The aim is that we don't have to open all files just for the columns names.\n",
    "\n",
    "Also, the following code filter on datasets so that it only uses the **generated variables** datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave 1 has 151 unique columns.\n",
      "Wave 2 has 452 unique columns.\n",
      "Wave 3 has 839 unique columns.\n",
      "Wave 4 has 89 unique columns.\n",
      "Wave 5 has 442 unique columns.\n",
      "Wave 6 has 443 unique columns.\n",
      "Wave 7 has 853 unique columns.\n",
      "Wave 8 has 7236 unique columns.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_info.csv')\n",
    "df = df[df['is_gv'] == True] # only keep the general variables files)\n",
    "\n",
    "# iterate through the waves\n",
    "for wave in range(1,9):\n",
    "    columns_properties = pd.DataFrame()\n",
    "    subset = df[df['wave'] == wave]\n",
    "\n",
    "    # iterate through the files in the wave\n",
    "    for columns,filename in zip(subset['columns'],subset['file_name']):\n",
    "        \n",
    "        # get all columns and the file they belong to\n",
    "        row = list(columns[1:-1].replace(\"'\", \"\").split(', '))\n",
    "        filenames = [filename]*len(row)\n",
    "\n",
    "        # add the columns and the file to the dataframe\n",
    "        temp = pd.DataFrame({'column': row, 'file_name': filenames})\n",
    "        columns_properties = pd.concat([columns_properties, temp])\n",
    "\n",
    "    columns_properties.drop_duplicates(inplace=True)\n",
    "    print(f'Wave {wave} has {len(columns)} unique columns.')\n",
    "\n",
    "    # save as csv file\n",
    "    columns_properties.to_csv(f'columns/wave_{wave}_columns.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
