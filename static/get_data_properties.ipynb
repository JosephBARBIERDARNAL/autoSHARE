{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all datasets properties and store them\n",
    "\n",
    "### Code\n",
    "\n",
    "The following code **iterates over all files** in the root directory containing all SHARE datasets. It extracts the properties of each dataset and stores them in a pandas dataframe. The properties are:\n",
    "- dataset name\n",
    "- wave\n",
    "- number of rows\n",
    "- number of columns\n",
    "- column names\n",
    "\n",
    "### Details\n",
    "\n",
    "- For some reason, one or multiple files, when trying to read them, throw a `ValueError`. However, `pandas` gives us the solution by telling us we should add `convert_categoricals=False` to the `read_csv` function when this is happening. This is the reason why we have a `try` and `except` block in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:47,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when opening:\n",
      "  data/sharew7_rel9-0-0_ALL_datasets_stata/sharew7_rel9-0-0_ra.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:36, 15.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# initiate constants\n",
    "directory = 'data/'\n",
    "file_names = []\n",
    "waves = []\n",
    "n_rows = []\n",
    "n_columns = []\n",
    "columns = []\n",
    "labels = []\n",
    "\n",
    "# special case that we want to skip\n",
    "def is_special_case(file):\n",
    "    \"\"\"\n",
    "    Check if the file is a special case that we want to skip.\n",
    "    Special cases are files such as imputation files and technical variables.\n",
    "\n",
    "    Parameters:\n",
    "    file (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the file is a special case, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    special_cases = [\n",
    "        'imputation',\n",
    "        'technical_variables',\n",
    "        'dropoff',\n",
    "        'children',\n",
    "        'exrates',\n",
    "        'vignettes',\n",
    "        'weights',\n",
    "        'interviewer',\n",
    "        'ilextra',\n",
    "        'cv_r'\n",
    "    ]\n",
    "    for special_case in special_cases:\n",
    "        if special_case in file:\n",
    "            return True\n",
    "\n",
    "# iterate through all files in the directory\n",
    "for root, dirs, files in tqdm(os.walk(directory)):\n",
    "    for file in files:\n",
    "        if file.endswith('.dta'):\n",
    "\n",
    "            # skip special cases\n",
    "            if is_special_case(file):\n",
    "                # skip and continue with the next file\n",
    "                continue \n",
    "            try:\n",
    "                dataset, meta = pyreadstat.read_dta(os.path.join(root, file))\n",
    "\n",
    "                column_names = list(meta.column_names)\n",
    "                column_labels = [label.replace(',', '') for label in meta.column_labels]\n",
    "\n",
    "                if len(column_names) != len(column_labels):\n",
    "                    print(f'different number of column names and labels in {file}')\n",
    "                    print(f'column names: {len(column_names)}')\n",
    "                    print(f'column labels: {len(column_labels)}')\n",
    "            except:\n",
    "                print('Error when opening:\\n ', os.path.join(root, file))\n",
    "\n",
    "            # get all meta data from current file\n",
    "            file_names.append(file)\n",
    "            waves.append(file[6])\n",
    "            n_rows.append(len(dataset))\n",
    "            n_columns.append(len(dataset.columns))\n",
    "            columns.append(column_names)\n",
    "            labels.append(column_labels)\n",
    "\n",
    "# create a dataframe with the results\n",
    "df = pd.DataFrame({\n",
    "    'file_name': file_names,\n",
    "    'wave': waves,\n",
    "    'n_rows': n_rows,\n",
    "    'n_columns': n_columns,\n",
    "    'columns': columns,\n",
    "    'labels': labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>wave</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_columns</th>\n",
       "      <th>columns</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sharew2_rel9-0-0_hh.dta</td>\n",
       "      <td>2</td>\n",
       "      <td>37132</td>\n",
       "      <td>21</td>\n",
       "      <td>[mergeid, hhid2, mergeidp2, coupleid2, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>sharew6_rel9-0-0_dn.dta</td>\n",
       "      <td>6</td>\n",
       "      <td>68055</td>\n",
       "      <td>145</td>\n",
       "      <td>[mergeid, hhid6, mergeidp6, coupleid6, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sharew3_rel9-0-0_dq.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>28454</td>\n",
       "      <td>177</td>\n",
       "      <td>[mergeid, hhid3, mergeidp3, coupleid3, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sharew5_rel9-0-0_iv.dta</td>\n",
       "      <td>5</td>\n",
       "      <td>66038</td>\n",
       "      <td>27</td>\n",
       "      <td>[mergeid, hhid5, mergeidp5, coupleid5, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>sharew3_rel9-0-0_hs.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>28454</td>\n",
       "      <td>175</td>\n",
       "      <td>[mergeid, hhid3, mergeidp3, coupleid3, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sharew2_rel9-0-0_br.dta</td>\n",
       "      <td>2</td>\n",
       "      <td>37132</td>\n",
       "      <td>23</td>\n",
       "      <td>[mergeid, hhid2, mergeidp2, coupleid2, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>sharew8_rel9-0-0_gs.dta</td>\n",
       "      <td>8</td>\n",
       "      <td>53695</td>\n",
       "      <td>23</td>\n",
       "      <td>[mergeid, hhid8, mergeidp8, coupleid8, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sharew7_rel9-0-0_ch.dta</td>\n",
       "      <td>7</td>\n",
       "      <td>77181</td>\n",
       "      <td>1616</td>\n",
       "      <td>[mergeid, hhid7, mergeidp7, coupleid7, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sharew4_rel9-0-0_xt.dta</td>\n",
       "      <td>4</td>\n",
       "      <td>1174</td>\n",
       "      <td>172</td>\n",
       "      <td>[mergeid, hhid4, country, language_xt, gender_...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharew5_rel9-0-0_ac.dta</td>\n",
       "      <td>5</td>\n",
       "      <td>66038</td>\n",
       "      <td>38</td>\n",
       "      <td>[mergeid, hhid5, mergeidp5, coupleid5, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name wave  n_rows  n_columns  \\\n",
       "89   sharew2_rel9-0-0_hh.dta    2   37132         21   \n",
       "191  sharew6_rel9-0-0_dn.dta    6   68055        145   \n",
       "210  sharew3_rel9-0-0_dq.dta    3   28454        177   \n",
       "18   sharew5_rel9-0-0_iv.dta    5   66038         27   \n",
       "211  sharew3_rel9-0-0_hs.dta    3   28454        175   \n",
       "96   sharew2_rel9-0-0_br.dta    2   37132         23   \n",
       "149  sharew8_rel9-0-0_gs.dta    8   53695         23   \n",
       "134  sharew7_rel9-0-0_ch.dta    7   77181       1616   \n",
       "37   sharew4_rel9-0-0_xt.dta    4    1174        172   \n",
       "2    sharew5_rel9-0-0_ac.dta    5   66038         38   \n",
       "\n",
       "                                               columns  \\\n",
       "89   [mergeid, hhid2, mergeidp2, coupleid2, country...   \n",
       "191  [mergeid, hhid6, mergeidp6, coupleid6, country...   \n",
       "210  [mergeid, hhid3, mergeidp3, coupleid3, country...   \n",
       "18   [mergeid, hhid5, mergeidp5, coupleid5, country...   \n",
       "211  [mergeid, hhid3, mergeidp3, coupleid3, country...   \n",
       "96   [mergeid, hhid2, mergeidp2, coupleid2, country...   \n",
       "149  [mergeid, hhid8, mergeidp8, coupleid8, country...   \n",
       "134  [mergeid, hhid7, mergeidp7, coupleid7, country...   \n",
       "37   [mergeid, hhid4, country, language_xt, gender_...   \n",
       "2    [mergeid, hhid5, mergeidp5, coupleid5, country...   \n",
       "\n",
       "                                                labels  \n",
       "89   [Person identifier (fix across modules and wav...  \n",
       "191  [Person identifier (fix across modules and wav...  \n",
       "210  [Person identifier (fix across modules and wav...  \n",
       "18   [Person identifier (fix across modules and wav...  \n",
       "211  [Person identifier (fix across modules and wav...  \n",
       "96   [Person identifier (fix across modules and wav...  \n",
       "149  [Person identifier (fix across modules and wav...  \n",
       "134  [Person identifier (fix across modules and wav...  \n",
       "37   [Person identifier (fix across modules and wav...  \n",
       "2    [Person identifier (fix across modules and wav...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminate normal and particular datasets\n",
    "\n",
    "According to the [official documentation](https://share-eric.eu/data/faqs-support):\n",
    "\n",
    "*\"The naming of variables is harmonised across waves. Variable names in the CAPI instrument data use the following format: mmXXXyyy_LL. “mm” is the module identifier, e.g. DN for the demographics module, “XXX” refers to the question number, e.g. 001, and “yyy” are optional digits for dummy variables (indicated by “d”), euro conversion (indicated by “e”) or unfolding brackets (indicated by “ub”). The separation character “_” is followed by “LL” optional digits for category or loop indication (“outer loop”).\"*\n",
    "\n",
    "For this reason, we add **boolean indicator** columns to the dataframe to discriminate normal datasets from particular ones. This allows us to see that approximately 10% of the datasets are particular, and maybe useless for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>wave</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_columns</th>\n",
       "      <th>columns</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>is_gv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>sharew9_rel9-0-0_br.dta</td>\n",
       "      <td>9</td>\n",
       "      <td>69447</td>\n",
       "      <td>25</td>\n",
       "      <td>[mergeid, hhid9, mergeidp9, coupleid9, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>sharew3_rel9-0-0_dq.dta</td>\n",
       "      <td>3</td>\n",
       "      <td>28454</td>\n",
       "      <td>177</td>\n",
       "      <td>[mergeid, hhid3, mergeidp3, coupleid3, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sharew5_rel9-0-0_ex.dta</td>\n",
       "      <td>5</td>\n",
       "      <td>66038</td>\n",
       "      <td>23</td>\n",
       "      <td>[mergeid, hhid5, mergeidp5, coupleid5, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sharew1_rel9-0-0_iv.dta</td>\n",
       "      <td>1</td>\n",
       "      <td>30416</td>\n",
       "      <td>42</td>\n",
       "      <td>[mergeid, hhid1, mergeidp1, coupleid1, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sharew4_rel9-0-0_ho.dta</td>\n",
       "      <td>4</td>\n",
       "      <td>57982</td>\n",
       "      <td>88</td>\n",
       "      <td>[mergeid, hhid4, mergeidp4, coupleid4, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sharew5_rel9-0-0_gv_housing.dta</td>\n",
       "      <td>5</td>\n",
       "      <td>66038</td>\n",
       "      <td>11</td>\n",
       "      <td>[mergeid, hhid5, mergeidp5, coupleid5, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>sharew2_rel9-0-0_ch.dta</td>\n",
       "      <td>2</td>\n",
       "      <td>37132</td>\n",
       "      <td>223</td>\n",
       "      <td>[mergeid, hhid2, mergeidp2, coupleid2, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sharew4_rel9-0-0_sn.dta</td>\n",
       "      <td>4</td>\n",
       "      <td>57982</td>\n",
       "      <td>56</td>\n",
       "      <td>[mergeid, hhid4, mergeidp4, coupleid4, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>sharew9_rel9-0-0_xt.dta</td>\n",
       "      <td>9</td>\n",
       "      <td>3491</td>\n",
       "      <td>220</td>\n",
       "      <td>[mergeid, hhid9, country, language_xt, gender_...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>sharew9_rel9-0-0_iv.dta</td>\n",
       "      <td>9</td>\n",
       "      <td>69447</td>\n",
       "      <td>26</td>\n",
       "      <td>[mergeid, hhid9, mergeidp9, coupleid9, country...</td>\n",
       "      <td>[Person identifier (fix across modules and wav...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_name wave  n_rows  n_columns  \\\n",
       "218          sharew9_rel9-0-0_br.dta    9   69447         25   \n",
       "210          sharew3_rel9-0-0_dq.dta    3   28454        177   \n",
       "8            sharew5_rel9-0-0_ex.dta    5   66038         23   \n",
       "54           sharew1_rel9-0-0_iv.dta    1   30416         42   \n",
       "28           sharew4_rel9-0-0_ho.dta    4   57982         88   \n",
       "23   sharew5_rel9-0-0_gv_housing.dta    5   66038         11   \n",
       "76           sharew2_rel9-0-0_ch.dta    2   37132        223   \n",
       "47           sharew4_rel9-0-0_sn.dta    4   57982         56   \n",
       "221          sharew9_rel9-0-0_xt.dta    9    3491        220   \n",
       "213          sharew9_rel9-0-0_iv.dta    9   69447         26   \n",
       "\n",
       "                                               columns  \\\n",
       "218  [mergeid, hhid9, mergeidp9, coupleid9, country...   \n",
       "210  [mergeid, hhid3, mergeidp3, coupleid3, country...   \n",
       "8    [mergeid, hhid5, mergeidp5, coupleid5, country...   \n",
       "54   [mergeid, hhid1, mergeidp1, coupleid1, country...   \n",
       "28   [mergeid, hhid4, mergeidp4, coupleid4, country...   \n",
       "23   [mergeid, hhid5, mergeidp5, coupleid5, country...   \n",
       "76   [mergeid, hhid2, mergeidp2, coupleid2, country...   \n",
       "47   [mergeid, hhid4, mergeidp4, coupleid4, country...   \n",
       "221  [mergeid, hhid9, country, language_xt, gender_...   \n",
       "213  [mergeid, hhid9, mergeidp9, coupleid9, country...   \n",
       "\n",
       "                                                labels  is_normal  is_gv  \n",
       "218  [Person identifier (fix across modules and wav...       True  False  \n",
       "210  [Person identifier (fix across modules and wav...       True  False  \n",
       "8    [Person identifier (fix across modules and wav...       True  False  \n",
       "54   [Person identifier (fix across modules and wav...       True  False  \n",
       "28   [Person identifier (fix across modules and wav...       True  False  \n",
       "23   [Person identifier (fix across modules and wav...       True   True  \n",
       "76   [Person identifier (fix across modules and wav...       True  False  \n",
       "47   [Person identifier (fix across modules and wav...       True  False  \n",
       "221  [Person identifier (fix across modules and wav...       True  False  \n",
       "213  [Person identifier (fix across modules and wav...       True  False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_file_normal(file_name: str, only_gv: bool=True) -> bool:\n",
    "    \"\"\"\n",
    "    Detect if the last 3 elements of the string follow the pattern _ab, \n",
    "    where 'a' and 'b' are single letters.\n",
    "    \n",
    "    Args:\n",
    "    - file_name (str): The string to be checked.\n",
    "    Returns:\n",
    "    - bool: True if the pattern is found, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # special case the General Variables files\n",
    "    if '_gv_' in file_name:\n",
    "        return True\n",
    "    \n",
    "    if only_gv:\n",
    "        return False\n",
    "    \n",
    "    # get file extension\n",
    "    suffix = file_name[:-4]\n",
    "\n",
    "    # check if the suffix is long enough\n",
    "    if len(suffix) < 3:\n",
    "        return False\n",
    "    \n",
    "    # check if the last three elements follow the pattern\n",
    "    last_three = suffix[-3:]\n",
    "    if last_three[0] == '_' and last_three[1].isalpha() and last_three[2].isalpha():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# filter out the files that are not normal\n",
    "df['is_normal'] = df['file_name'].apply(is_file_normal, only_gv=False)\n",
    "df['is_gv'] = df['file_name'].apply(is_file_normal, only_gv=True)\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('data_info.csv', index=False)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_normal\n",
      "True    100.0\n",
      "Name: count, dtype: float64 \n",
      "\n",
      "is_gv\n",
      "False    83.26\n",
      "True     16.74\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(round(df.is_normal.value_counts()/len(df)*100,2), '\\n')\n",
    "print(round(df.is_gv.value_counts()/len(df)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get column names for each wave\n",
    "\n",
    "We store the column names for each wave in `.csv` files, so we can use them later. The aim is that we don't have to open all files just for the columns names.\n",
    "\n",
    "For the variable selection feature, we only want to **keep relevant variables**. For this, we filter on variables that are not identifiers (such as `mergeid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_to_remove = ['mergeid', 'hhid', 'coupleid'] \n",
    "\n",
    "def is_valid_column(col_name, patterns_to_remove=patterns_to_remove):\n",
    "    \"\"\"\n",
    "    Check if a column name is not an identifier.\n",
    "    \n",
    "    Example: if a column is named 'mergeid6', it respects the\n",
    "    pattern 'mergeid' and should be removed.\n",
    "    \n",
    "    Args:\n",
    "    - col_name (str): The column name to be checked.\n",
    "    - patterns_to_remove (list): A list of patterns to be removed.\n",
    "    Returns:\n",
    "    - bool: True if the column name is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    for pattern in patterns_to_remove:\n",
    "        if pattern in col_name:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta', 'sharew1_rel9-0-0_hc.dta']\n",
      "157\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(filenames)\n\u001b[1;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(filenames))\n\u001b[0;32m---> 19\u001b[0m     temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\n\u001b[1;32m     20\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mcolumn\u001b[39;49m\u001b[39m'\u001b[39;49m: row,\n\u001b[1;32m     21\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m: label,\n\u001b[1;32m     22\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mfile_name\u001b[39;49m\u001b[39m'\u001b[39;49m: filenames})\n\u001b[1;32m     23\u001b[0m     columns_properties \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([columns_properties, temp])\n\u001b[1;32m     25\u001b[0m columns_properties\u001b[39m.\u001b[39mdrop_duplicates(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/autoSHARE/venv/lib/python3.10/site-packages/pandas/core/frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    761\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    762\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    763\u001b[0m     )\n\u001b[1;32m    765\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    766\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    768\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    769\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/Desktop/autoSHARE/venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/Desktop/autoSHARE/venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Desktop/autoSHARE/venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_info.csv')\n",
    "\n",
    "# iterate through the waves\n",
    "for wave in range(1,9+1):\n",
    "    columns_properties = pd.DataFrame()\n",
    "    subset = df[df['wave'] == wave]\n",
    "\n",
    "    # iterate through the files in the wave\n",
    "    for columns,labels,filename in zip(subset['columns'],subset['labels'],subset['file_name']):\n",
    "        \n",
    "        # get all columns and the file they belong to\n",
    "        row = list(columns[1:-1].replace(\"'\", \"\").split(', '))\n",
    "        label = list(labels[1:-1].replace(\"'\", \"\").split(', '))\n",
    "        filenames = [filename]*len(row)\n",
    "\n",
    "        # add the columns and the file to the dataframe\n",
    "        print(filenames)\n",
    "        print(len(filenames))\n",
    "        temp = pd.DataFrame({\n",
    "            'column': row,\n",
    "            'labels': label,\n",
    "            'file_name': filenames})\n",
    "        columns_properties = pd.concat([columns_properties, temp])\n",
    "\n",
    "    columns_properties.drop_duplicates(inplace=True)\n",
    "    print(f'Wave {wave} has {len(columns)} unique columns.')\n",
    "\n",
    "    # remove all column names dupplicate (keep first occurence)\n",
    "    columns_properties.drop_duplicates(subset='column', keep='first', inplace=True)\n",
    "\n",
    "    # remove all columns that are identifiers\n",
    "    columns_properties['is_valid'] = columns_properties['column'].apply(is_valid_column)\n",
    "    columns_properties = columns_properties[columns_properties['is_valid'] == True]\n",
    "\n",
    "    # save as csv file\n",
    "    #columns_properties.to_csv(f'columns/wave_{wave}_columns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create basic dataset per wave\n",
    "\n",
    "The aim of this code is to create a basic/dummy dataset per wave. This dataset contains the following columns:\n",
    "\n",
    "- `mergeid`: identifier of the respondent\n",
    "- `country`: country of the respondent\n",
    "- `language`: language of the respondent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  4.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for wave in tqdm(range(1,9+1)):\n",
    "    df = pd.read_stata(f'data/sharew{wave}_rel9-0-0_ALL_datasets_stata/sharew{wave}_rel9-0-0_ac.dta')\n",
    "    df = df[['country', 'mergeid', 'language']]\n",
    "    df.to_stata(f'data/sharew{wave}_rel9-0-0_ALL_datasets_stata/wave{wave}_dummy.stata', write_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
